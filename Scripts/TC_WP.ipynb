{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from pydot import Dot, Edge, Node\n",
    "from automata.fa.dfa import DFA\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "from distances import  custom_distanceW\n",
    "import itertools\n",
    "from time import time\n",
    "\n",
    "def data_preprocess1():\n",
    "\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(r'C:\\Users\\bchan\\Downloads\\Dodgers\\univariate\\Dodgers\\101-freeway-traffic.test.csv')\n",
    "\n",
    "    # Convert the 'timestamp' column to datetime format\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "    # Add a new column for day of the week (0 = Monday, 6 = Sunday)\n",
    "    df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
    "\n",
    "    # Filter only rows corresponding to each days\n",
    "    mon = df[df['day_of_week'] == 0]\n",
    "    tue = df[df['day_of_week'] == 1]\n",
    "    wed = df[df['day_of_week'] == 2]\n",
    "    thu = df[df['day_of_week'] == 3]\n",
    "    fri = df[df['day_of_week'] == 4]\n",
    "    sat = df[df['day_of_week'] == 5]\n",
    "    sun = df[df['day_of_week'] == 6]\n",
    "\n",
    "    sun_list, mon_list, tue_list, wed_list, thu_list, fri_list, sat_list =[], [], [], [], [], [], []\n",
    "    sun_label, mon_label, tue_label, wed_label, thu_label, fri_label, sat_label=[], [], [], [], [], [], []\n",
    "\n",
    "    #288 data points corresponds to 1day(24hrs). 1hrs-12obs. 6hrs-72 obs\n",
    "    for i in range(0, len(sun['count'].values), 288):\n",
    "        #print(f'i:{i}')\n",
    "        if -1 not in sun['count'].values[i:i+288] and 1 not in sun['is_anomaly'].values[i:i+288]:\n",
    "            sun_list.append([sum(sun['count'].values[j:j+72]) for j in range(i, i+288, 72)])\n",
    "            sun_label.append([sum(sun['is_anomaly'].values[j:j+72]) for j in range(i, i+288, 72)])\n",
    "        if -1 not in mon['count'].values[i:i+288]:\n",
    "            mon_list.append([sum(mon['count'].values[j:j+72]) for j in range(i, i+288, 72)])\n",
    "            mon_label.append([sum(mon['is_anomaly'].values[j:j+72]) for j in range(i, i+288, 72)])\n",
    "        if -1 not in tue['count'].values[i:i+288]:\n",
    "            tue_list.append([sum(tue['count'].values[j:j+72]) for j in range(i, i+288, 72)])\n",
    "            tue_label.append([sum(tue['is_anomaly'].values[j:j+72]) for j in range(i, i+288, 72)])\n",
    "        if -1 not in wed['count'].values[i:i+288]:\n",
    "            wed_list.append([sum(wed['count'].values[j:j+72]) for j in range(i, i+288, 72)])\n",
    "            wed_label.append([sum(wed['is_anomaly'].values[j:j+72]) for j in range(i, i+288, 72)])\n",
    "        if -1 not in thu['count'].values[i:i+288]:\n",
    "            thu_list.append([sum(thu['count'].values[j:j+72]) for j in range(i, i+288, 72)])\n",
    "            thu_label.append([sum(thu['is_anomaly'].values[j:j+72]) for j in range(i, i+288, 72)])\n",
    "        if -1 not in fri['count'].values[i:i+288] and 1 not in fri['is_anomaly'].values[i:i+288]:\n",
    "            fri_list.append([sum(fri['count'].values[j:j+72]) for j in range(i, i+288, 72)])\n",
    "            fri_label.append([sum(fri['is_anomaly'].values[j:j+72]) for j in range(i, i+288, 72)])\n",
    "        if -1 not in sat['count'].values[i:i+288]:\n",
    "            sat_list.append([sum(sat['count'].values[j:j+72]) for j in range(i, i+288, 72)])\n",
    "            sat_label.append([sum(sat['is_anomaly'].values[j:j+72]) for j in range(i, i+288, 72)])\n",
    "    \n",
    "    rounded_satlist=[]\n",
    "    for i in sat_list:\n",
    "        rounded_satlist.append([round(j/100) for j in i])\n",
    "\n",
    "    #Create labels\n",
    "    G=[]\n",
    "    for i in sat_label:\n",
    "        if any(i):\n",
    "            G.append(1)\n",
    "        else:\n",
    "            G.append(0)\n",
    "        \n",
    "    #Adding normal sequence to increase the number of normal sequence\n",
    "    #for sat\n",
    "    repeat=[[3, 14, 20, 16], [3, 11, 17, 17], [4, 16, 19, 16],[3, 13, 18, 16], [4, 11, 18, 15], [4, 14, 20, 17], [4, 13, 18, 15],[4, 13, 17, 13]]\n",
    "    i=0\n",
    "    while i < 11:    \n",
    "        for r in repeat:\n",
    "            rounded_satlist.append(r)\n",
    "            G.append(0)\n",
    "        i+=1\n",
    "\n",
    "    #manual labelling of sequence considering very low traffic also as anamaly\n",
    "    G[0]=1\n",
    "    G[13]=1\n",
    "\n",
    "    FL_dist=rounded_satlist\n",
    "\n",
    "    FL_dist_test=[]\n",
    "    G_test=[]\n",
    "    for i in range(7):\n",
    "        FL_dist_test.append(rounded_satlist[i])\n",
    "        G_test.append(G[i])\n",
    "    for i in range(len(rounded_satlist)-15, len(rounded_satlist)):\n",
    "        FL_dist_test.append(rounded_satlist[i])\n",
    "        G_test.append(G[i])\n",
    "\n",
    "    Lst=[]\n",
    "    Lst_test=[]\n",
    "    for i in FL_dist:\n",
    "        Lst.append(str(i)[1:-1].replace(' ',''))\n",
    "    for i in FL_dist_test:\n",
    "        Lst_test.append(str(i)[1:-1].replace(' ',''))\n",
    "\n",
    "    FL = [l.split(',') for l in Lst]\n",
    "    FL_test = [l.split(',') for l in Lst_test]\n",
    "\n",
    "    uniq_list=set(Lst)\n",
    "    alphabet = set(item for string in uniq_list for item in string.split(\",\") if item != ',')\n",
    "\n",
    "    Pref_S = set()\n",
    "    for string in uniq_list:\n",
    "        prefixes = string.split(',')\n",
    "        for i in range(1, len(prefixes) + 1):\n",
    "            prefix = ','.join(prefixes[:i])\n",
    "            Pref_S.add(prefix)\n",
    "    Pref_S.add('')\n",
    "    \n",
    "\n",
    "    dist = custom_distanceW(np.array(FL_dist))\n",
    "    #print(f'Max Distance: {np.max(dist)}')\n",
    "    #np.savetxt('C:/Users/bchan/Downloads/result_TC.txt', dist, fmt='%.0f')\n",
    "\n",
    "    return alphabet, Pref_S, Lst, FL, dist, FL_test, G_test\n",
    "\n",
    "def train(n, eps, eps1, eps2):\n",
    "\n",
    "    alphabet, Pref_S, Lst, FL, dist, FL_test, G_test = data_preprocess1()\n",
    "    \n",
    "    states = {str(f'q{i}') for i in range(n)}\n",
    "    start_state = 'q0'\n",
    "\n",
    "    env=gp.Env(empty=True)\n",
    "    env.setParam('OutputFlag', 0)\n",
    "    env.start()\n",
    "    \n",
    "    #t0 = time()\n",
    "    # Creating a new model\n",
    "    mtc = gp.Model(\"DFA_TC\", env=env)\n",
    "\n",
    "    t0 = time()\n",
    "\n",
    "    #DECISION VARIABLES\n",
    "    delta = mtc.addVars(states, alphabet, states, vtype=gp.GRB.BINARY, name='delta')\n",
    "    x = mtc.addVars(Pref_S, states, vtype=gp.GRB.BINARY, name='x')\n",
    "    f = mtc.addVars(states, vtype=gp.GRB.BINARY, name='f')\n",
    "    alpha = mtc.addVars(len(Lst), states, vtype=gp.GRB.BINARY, name= 'alpha')\n",
    "    beta = mtc.addVars(len(Lst), states, vtype=gp.GRB.BINARY, name= 'beta')\n",
    "\n",
    "    #OBJECTIVE\n",
    "    lambda_nn = len(Lst)*(len(Lst)-1)*np.max(dist)\n",
    "    #print(lambda_nn)\n",
    "    print(f'eps: {eps}, eps1: {eps1}, eps2: {eps2}')\n",
    "    mtc.setObjective(sum(beta[i,state1]*beta[k, state2]*dist[i,k]*(eps/lambda_nn) for i,_ in enumerate(Lst) for state1 in states for k,_ in enumerate(Lst) for state2 in states if dist[i,k] != 0) \\\n",
    "                    + sum(alpha[k,state2]*(eps1/len(Lst)) for k,_ in enumerate(Lst) for state2 in states) \\\n",
    "                    + sum(delta[state1,symbol,state2]*eps2 for state1 in states for symbol in alphabet for state2 in states if state1 != state2),\\\n",
    "                     gp.GRB.MINIMIZE)\n",
    "    \n",
    "    #AUTOMATA CONSTRAINTS\n",
    "    #Constraint1\n",
    "    for state0 in states:\n",
    "        for symbol in alphabet:\n",
    "            mtc.addConstr(sum(delta[state0,symbol,state1] for state1 in states)==1, name=f'delta[{state0},{symbol}]')\n",
    "\n",
    "    #Constraint2\n",
    "    for word in Pref_S:\n",
    "        mtc.addConstr(sum(x[word,state1] for state1 in states)==1, name=f'x[{word}]')\n",
    "\n",
    "    #Constraint3\n",
    "    mtc.addConstr(x['',start_state]==1, name='initial_state')\n",
    "\n",
    "    #Constraint4 \n",
    "    for state0, word, symbol, state1 in itertools.product(states, Pref_S, alphabet, states):\n",
    "        if (word + ',' + symbol) in Pref_S:\n",
    "            mtc.addConstr(x[word, state0] + delta[state0, symbol, state1] - 1 <= x[word + ',' + symbol, state1], name=f'transition[{state0},{word},{symbol},{state1}]')\n",
    "        if word == '' and symbol in Pref_S:\n",
    "            mtc.addConstr(x[word, state0] + delta[state0, symbol, state1] - 1 <= x[symbol, state1], name=f'transition[{state0},{word},{symbol},{state1}]')\n",
    "\n",
    "    #BOUND CONSTRAINTS\n",
    "    for i, word in enumerate(Lst):\n",
    "        for state1 in states:\n",
    "            mtc.addConstr(alpha[i, state1] >= x[word,state1] + f[state1] -1, name=f'bound_1[{state1},{i}]')        \n",
    "\n",
    "    for i, word in enumerate(Lst):\n",
    "        for state1 in states:\n",
    "            mtc.addConstr(alpha[i, state1] <= x[word,state1], name=f'bound_2[{state1},{i}]')\n",
    "\n",
    "    for i, word in enumerate(Lst):\n",
    "        for state1 in states:\n",
    "            mtc.addConstr(alpha[i, state1] <= f[state1], name=f'bound_3[{state1},{i}]')\n",
    "    \n",
    "    #not valid MILP constraint\n",
    "    '''\n",
    "    for i, word in enumerate(Lst):\n",
    "        for state1 in states:\n",
    "            mtc.addConstr(x[word, state1] * (1-f[state1]) == beta[i, state1], name=f'bound_4[{state1},{i}]')\n",
    "    '''\n",
    "    for i, word in enumerate(Lst):\n",
    "        for state1 in states:\n",
    "            mtc.addConstr(beta[i, state1] >= x[word,state1] + (1-f[state1]) -1, name=f'bound_5[{state1},{i}]')\n",
    "            mtc.addConstr(beta[i, state1] <= x[word,state1], name=f'bound_6[{state1},{i}]')\n",
    "            mtc.addConstr(beta[i, state1] <= (1-f[state1]), name=f'bound_7[{state1},{i}]')            \n",
    "    \n",
    "    mtc.optimize()\n",
    "    t1 = time()\n",
    "    print(\"Run time\", (t1-t0), \"seconds\")\n",
    "    mtc.write(rf'C:\\Users\\bchan\\Desktop\\TUD\\Thesis\\model_TC_{n}.lp')\n",
    "\n",
    "    #print('Obj Value: %g' % mtc.ObjVal)\n",
    "    #print(f\"Alpha: {mtc.getAttr('X', alpha)}\")\n",
    "    #print(f\"Beta: {mtc.getAttr('X', beta)}\")\n",
    "\n",
    "    if mtc.status == 1:\n",
    "        status = 'LOADED'\n",
    "        print(f'DFAmodel_{n} LOADED')\n",
    "        #dfa1 = DFA(states=states,input_symbols=alphabet, transitions= transition_dict, initial_state= start_state, final_states={'q0'})\n",
    "    \n",
    "    elif mtc.status == 2:\n",
    "        print(f'DFAmodel_{n} OPTIMAL')\n",
    "        status='OPTIMAL'\n",
    "        transitions = mtc.getAttr('X', delta)\n",
    "        t_values = [(s1,a,s2) for s1 in states for s2 in states for a in alphabet if round(transitions[s1, a, s2],0) == 1]\n",
    "        #for t in t_values:\n",
    "            #print(t)\n",
    "        f_s = mtc.getAttr('X', f)\n",
    "        final_state = {s1 for s1 in states if round(f_s[s1],0) == 1}\n",
    "\n",
    "        transition_dict = create_transition_dict(states, alphabet, t_values)\n",
    "        #print(transition_dict)\n",
    "\n",
    "        dfa1 = DFA(states=states,input_symbols=alphabet, transitions= transition_dict, initial_state= start_state, final_states=final_state)\n",
    "        accepted = 0\n",
    "        rejected = 0\n",
    "        for w in FL:\n",
    "            if dfa1.accepts_input(w):\n",
    "                #print(f'{w}:accepted')\n",
    "                accepted += 1             \n",
    "            else:\n",
    "                #print(f'{w}:rejected')\n",
    "                rejected += 1        \n",
    "        print(f'Accepted in Training:{accepted}')\n",
    "        print(f'Rejected in Training:{rejected}')\n",
    "\n",
    "        create_diagram(rf'C:\\Users\\bchan\\Desktop\\TUD\\Thesis\\diagram_TC_{n}.png', states, start_state,final_state, transition_dict)\n",
    "        return dfa1, FL_test, G_test      \n",
    "    \n",
    "    elif mtc.status == 3:\n",
    "        status = 'INFEASIBLE'\n",
    "        print(f'DFAmodel_{n} INFEASIBLE')\n",
    "    else:\n",
    "        print('status unknown, DEBUG!!')    \n",
    " \n",
    "    return status\n",
    "\n",
    "def create_transition_dict(states, alphabet, t_values):\n",
    "    transition_dict = {}\n",
    "\n",
    "    for state in states:\n",
    "        transition_dict[state] = {}\n",
    "        for symbol in alphabet:\n",
    "            transition_dict[state][symbol] = None\n",
    "\n",
    "    for trans in t_values:\n",
    "        current_state, symbol, next_state = trans\n",
    "        transition_dict[current_state][symbol] = next_state\n",
    "\n",
    "    return transition_dict\n",
    "\n",
    "def create_diagram(path, states, start_state, final_state, transition_dict):\n",
    "\n",
    "    graph = Dot(graph_type='digraph', rankdir='LR')\n",
    "    nodes = {}\n",
    "    for state in states:\n",
    "        if state == start_state:\n",
    "            # color start state with green\n",
    "            if state in final_state:\n",
    "                initial_state_node = Node(\n",
    "                    state,\n",
    "                    style='filled',\n",
    "                    peripheries=2,\n",
    "                    fillcolor='#66cc33')\n",
    "            else:\n",
    "                initial_state_node = Node(\n",
    "                    state, style='filled', fillcolor='#66cc33')\n",
    "            nodes[state] = initial_state_node\n",
    "            graph.add_node(initial_state_node)\n",
    "        else:\n",
    "            if state in final_state:\n",
    "                state_node = Node(state, peripheries=2)\n",
    "            else:\n",
    "                state_node = Node(state)\n",
    "            nodes[state] = state_node\n",
    "            graph.add_node(state_node)\n",
    "    # adding edges\n",
    "    for from_state, lookup in transition_dict.items():\n",
    "        for to_label, to_state in lookup.items():\n",
    "            graph.add_edge(Edge(\n",
    "                nodes[from_state],\n",
    "                nodes[to_state],\n",
    "                label=to_label\n",
    "            ))\n",
    "    if path:\n",
    "        graph.write_png(path)\n",
    "    return graph\n",
    "\n",
    "def test(G_test, FL_test, dfa1):\n",
    "    accepted = 0\n",
    "    rejected = 0\n",
    "    Predicted_labels=[]\n",
    "\n",
    "    for w in FL_test:\n",
    "        #print(w)\n",
    "        if dfa1.accepts_input(w):\n",
    "            Predicted_labels.append(1)\n",
    "            #print(f'{w}:accepted')\n",
    "            accepted += 1             \n",
    "        else:\n",
    "            #print(f'{w}:rejected')\n",
    "            Predicted_labels.append(0)\n",
    "            rejected += 1  \n",
    "    \n",
    "    print(f'Accepted in Testing:{accepted}')\n",
    "    print(f'Rejected in Testing:{rejected}')\n",
    "    #print(f'Predicted_labels:{Predicted_labels}')\n",
    "    #print(f'True_labelssssss:{G_test}')\n",
    "    \n",
    "    accuracy = accuracy_score(G_test, Predicted_labels)\n",
    "    print(f'Accuracy:{round(accuracy,2)}')\n",
    "    f1 = f1_score(G_test, Predicted_labels, average='binary', pos_label=1)\n",
    "    print(f'F1_score:{round(f1,2)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n denotes the number of states\n",
    "# eps, eps1, eps2 are regularization parameter\n",
    "for n in range(2,3):\n",
    "    for i, j, k in itertools.product([2], [1], [0]):\n",
    "        dfa1, FL_test, G_test = train(n, eps=i, eps1=j, eps2=k)\n",
    "        test(G_test, FL_test, dfa1)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
