{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removed weekends\n",
    "#got the average for each hour 0-1 [Mon-fri]=B_01, 1-2 [Mon-fri]=B_12, 2-3 [Mon-fri]=B_23 ... 23-24 [Mon-fri]=B2324\n",
    "#Now the data points, Lets say in 0-1 [Mon-fri] > 0.95*B_01 not an anomaly, else anomaly.  \n",
    "\n",
    "from statistics import mean\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from pydot import Dot, Edge, Node\n",
    "from automata.fa.dfa import DFA\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "import itertools\n",
    "from time import time\n",
    "\n",
    "with open('C:/Users/bchan/Desktop/TUD/gurobi/PD_dataset/train_data1.txt', \"r\") as my_file:\n",
    "        train_pow = [float(line.strip()) for line in my_file.readlines()]\n",
    "with open('C:/Users/bchan/Desktop/TUD/gurobi/PD_dataset/test_data1.txt', \"r\") as my_file:\n",
    "        test_pow = [float(line.strip()) for line in my_file.readlines()]\n",
    "\n",
    "sorted_data=sorted(train_pow+test_pow)\n",
    "\n",
    "def my_scaler(column,min_val,max_val):\n",
    "    range_val = sorted_data[-1]-sorted_data[0]\n",
    "    scaled_values = [round(((max_val - min_val)/range_val)*(i - sorted_data[0]) + min_val,1) for i in column]\n",
    "    return scaled_values\n",
    "\n",
    "scaled_values=my_scaler(train_pow,0,1)\n",
    "scaled_values1=my_scaler(test_pow,0,1)\n",
    "\n",
    "converted_num = [str(i) for i in scaled_values]\n",
    "converted_num1 = [str(i) for i in scaled_values1]\n",
    "Lst=converted_num\n",
    "Lst1=converted_num1\n",
    "FL = [l.split(',') for l in Lst]\n",
    "FL_test = [l.split(',') for l in Lst1]\n",
    "\n",
    "uniq_list=set(Lst)\n",
    "alphabet = set(item for string in uniq_list for item in string.split(\",\") if item != ',')\n",
    "\n",
    "Pref_S = set()\n",
    "for string in uniq_list:\n",
    "    prefixes = string.split(',')\n",
    "    for i in range(1, len(prefixes) + 1):\n",
    "        prefix = ','.join(prefixes[:i])\n",
    "        Pref_S.add(prefix)\n",
    "Pref_S.add('')\n",
    "\n",
    "def train(n):\n",
    "    #Function to train a model and return a DFA\n",
    "    #n denotes no of states, m denotes the ALFRED goal, lower and upper denotes the two bounds\n",
    "    \n",
    "    states = {str(f'q{i}') for i in range(n)}\n",
    "    start_state = 'q0'\n",
    "\n",
    "    env=gp.Env(empty=True)\n",
    "    env.setParam('OutputFlag', 0)\n",
    "    env.start()\n",
    "\n",
    "    #t0 = time()\n",
    "    # Creating a new model\n",
    "    mdb = gp.Model(\"DFA_DBPD\", env=env)\n",
    "\n",
    "    t0 = time()\n",
    "\n",
    "    #DECISION VARIABLES\n",
    "    delta = mdb.addVars(states, alphabet, states, vtype=gp.GRB.BINARY, name='delta')\n",
    "    x = mdb.addVars(Pref_S, states, vtype=gp.GRB.BINARY, name='x')\n",
    "    f = mdb.addVars(states, vtype=gp.GRB.BINARY, name='f')\n",
    "    alpha = mdb.addVars(len(Lst), states, vtype=gp.GRB.BINARY, name= 'alpha')\n",
    "    LB = mdb.addVar(lb=0.10,ub=0.10,vtype=gp.GRB.CONTINUOUS, name='LB')\n",
    "    UB = mdb.addVar(lb=0.11, ub=0.11,vtype=gp.GRB.CONTINUOUS, name='UB')\n",
    "\n",
    "    #OBJECTIVE\n",
    "    mdb.setObjective(1, gp.GRB.MINIMIZE)\n",
    "\n",
    "    #AUTOMATA CONSTRAINTS\n",
    "    #Constraint1\n",
    "    for state0 in states:\n",
    "        for symbol in alphabet:\n",
    "            mdb.addConstr(sum(delta[state0,symbol,state1] for state1 in states)==1, name=f'delta[{state0},{symbol}]')\n",
    "    \n",
    "    #Constraint2\n",
    "    for word in Pref_S:\n",
    "        mdb.addConstr(sum(x[word,state1] for state1 in states)==1, name=f'x[{word}]')\n",
    "\n",
    "\n",
    "    #Constraint3\n",
    "    mdb.addConstr(x['',start_state]==1, name='initial_state')\n",
    "\n",
    "    #Constraint4\n",
    "    for state0, word, symbol, state1 in itertools.product(states, Pref_S, alphabet, states):\n",
    "        if (word + ',' + symbol) in Pref_S:\n",
    "            mdb.addConstr(x[word,state0] + delta[state0, symbol, state1] -1 <= x[word + ',' + symbol, state1], name=f'transition[{state0},{word},{symbol},{state1}]')\n",
    "\n",
    "        if word == '' and symbol in Pref_S:\n",
    "            mdb.addConstr(x[word, state0] + delta[state0, symbol, state1] - 1 <= x[symbol, state1], name=f'transition[{state0},{word},{symbol},{state1}]')\n",
    "\n",
    "\n",
    "    #BOUND CONSTRAINTS\n",
    "    for i, word in enumerate(Lst):\n",
    "        for state1 in states:\n",
    "            mdb.addConstr(alpha[i, state1] >= x[word,state1] + f[state1] -1, name=f'bound_1[{state1},{i}]')\n",
    "            mdb.addConstr(alpha[i, state1] <= x[word,state1], name=f'bound_2[{state1},{i}]')\n",
    "            mdb.addConstr(alpha[i, state1] <= f[state1], name=f'bound_3[{state1},{i}]')        \n",
    "         \n",
    "    mdb.addConstr(sum(alpha[i, state1] for i,word in enumerate(Lst) for state1 in states )/len(Lst) >= LB, name=f'lowerBound')\n",
    "    mdb.addConstr(sum(alpha[i, state1] for i,word in enumerate(Lst) for state1 in states )/len(Lst) <= UB, name=f'upperBound')\n",
    "\n",
    "    #Write the model\n",
    "    mdb.write(rf'C:\\Users\\bchan\\Desktop\\TUD\\Thesis\\model_DB_{n}.lp')\n",
    "\n",
    "    mdb.optimize()\n",
    "    #print('Obj: %g' % mdb.ObjVal)\n",
    "\n",
    "    t1 = time()\n",
    "    #print(t1)\n",
    "    print(\"Run time\", (t1-t0), \"seconds\")\n",
    "\n",
    "    if mdb.status == 1:\n",
    "        status = 'LOADED'\n",
    "        print(f'DFAmodel_{n}: {status}')\n",
    "            \n",
    "    elif mdb.status == 2:\n",
    "        print(f'DFAmodel_{n} OPTIMAL')\n",
    "        status='OPTIMAL'\n",
    "        transitions = mdb.getAttr('X', delta)\n",
    "        t_values = [(s1,a,s2) for s1 in states for s2 in states for a in alphabet if round(transitions[s1, a, s2],0) == 1]\n",
    "        f_s = mdb.getAttr('X', f)\n",
    "        final_state = {s1 for s1 in states if round(f_s[s1],0) == 1}\n",
    "\n",
    "        transition_dict = create_transition_dict(states, alphabet, t_values)\n",
    "        \n",
    "        dfa1 = DFA(states=states,input_symbols=alphabet, transitions= transition_dict, initial_state= start_state, final_states=final_state)\n",
    "        #print(f'Final_state:{final_state}')\n",
    "        accepted = 0\n",
    "        rejected = 0\n",
    "        for w in FL:\n",
    "            if dfa1.accepts_input(w):\n",
    "                #print(f'{w}:accepted')\n",
    "                #print('accepted')\n",
    "                accepted += 1             \n",
    "            else:\n",
    "                rejected += 1        \n",
    "        print(f'Accepted:{accepted}')\n",
    "        print(f'Rejected:{rejected}')\n",
    "\n",
    "        create_diagram(rf'C:\\Users\\bchan\\Desktop\\TUD\\Thesis\\diagram_DB_{n}.png', states, start_state,final_state, transition_dict)\n",
    "        return dfa1    \n",
    "    \n",
    "    elif mdb.status == 3:\n",
    "        status = 'INFEASIBLE'\n",
    "        print(f'DFAmodel_{n}: {status}')\n",
    "    else:\n",
    "        print('status unknown, DEBUG!!')    \n",
    "\n",
    "\n",
    "def create_transition_dict(states, alphabet, t_values):\n",
    "    transition_dict = {}\n",
    "\n",
    "    for state in states:\n",
    "        transition_dict[state] = {}\n",
    "        for symbol in alphabet:\n",
    "            transition_dict[state][symbol] = None\n",
    "\n",
    "    for trans in t_values:\n",
    "        current_state, symbol, next_state = trans\n",
    "        transition_dict[current_state][symbol] = next_state\n",
    "\n",
    "    return transition_dict\n",
    "\n",
    "def create_diagram(path, states, start_state, final_state, transition_dict):\n",
    "\n",
    "    graph = Dot(graph_type='digraph', rankdir='LR')\n",
    "    nodes = {}\n",
    "    for state in states:\n",
    "        if state == start_state:\n",
    "            # color start state with green\n",
    "            if state in final_state:\n",
    "                initial_state_node = Node(\n",
    "                    state,\n",
    "                    style='filled',\n",
    "                    peripheries=2,\n",
    "                    fillcolor='#66cc33')\n",
    "            else:\n",
    "                initial_state_node = Node(\n",
    "                    state, style='filled', fillcolor='#66cc33')\n",
    "            nodes[state] = initial_state_node\n",
    "            graph.add_node(initial_state_node)\n",
    "        else:\n",
    "            if state in final_state:\n",
    "                state_node = Node(state, peripheries=2)\n",
    "            else:\n",
    "                state_node = Node(state)\n",
    "            nodes[state] = state_node\n",
    "            graph.add_node(state_node)\n",
    "    # adding edges\n",
    "    for from_state, lookup in transition_dict.items():\n",
    "        for to_label, to_state in lookup.items():\n",
    "            graph.add_edge(Edge(\n",
    "                nodes[from_state],\n",
    "                nodes[to_state],\n",
    "                label=to_label\n",
    "            ))\n",
    "    if path:\n",
    "        graph.write_png(path)\n",
    "    return graph\n",
    "\n",
    "def test( dfa1, FL_test):\n",
    "    with open('C:/Users/bchan/Desktop/TUD/gurobi/PD_dataset/test_label1.txt', \"r\") as my_file:\n",
    "        test_label = [int(line.strip()) for line in my_file.readlines()]\n",
    "    accepted = 0\n",
    "    rejected = 0\n",
    "    Predicted_labels=[]\n",
    "    for w in FL_test:\n",
    "        if dfa1.accepts_input(w):\n",
    "            Predicted_labels.append(1)\n",
    "            accepted += 1             \n",
    "        else:\n",
    "            Predicted_labels.append(0)\n",
    "            rejected += 1        \n",
    "    print(f'Accepted in Testing:{accepted}')\n",
    "    print(f'Rejected in Testing:{rejected}')    \n",
    "\n",
    "    accuracy = accuracy_score(test_label, Predicted_labels)\n",
    "    print(f'Accuracy:{round(accuracy,2)}')\n",
    "    f1 = f1_score(test_label, Predicted_labels, average='binary', pos_label=1)\n",
    "    print(f'F1_score:{round(f1,2)}\\n')\n",
    "\n",
    "for n in range(2,3):\n",
    "    dfa1= train(n)\n",
    "    test(dfa1, FL_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
